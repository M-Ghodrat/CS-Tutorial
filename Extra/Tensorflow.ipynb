{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "excess-philippines",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-simpson",
   "metadata": {},
   "source": [
    "As a motivating problem, let's say that you have some cost function $J$ that you want to minimize:\n",
    "\n",
    "$$\n",
    "J(w) = w^2 - 10w +25\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mechanical-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-words",
   "metadata": {},
   "source": [
    "The great thing about TensorFlow is you only have to implement forward prop, that is you only have to write the code to compute the value of the cost function. TensorFlow can figure out how to do the backprop or do the gradient computation. One way to do this is to use gradient tape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "animated-exhibition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(0, dtype=tf.float32) #initialize the variable to 0\n",
    "optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "\n",
    "def train_step():\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = w ** 2 - 10 * w +25\n",
    "    trainable_variables = [w]\n",
    "    grads = tape.gradient(cost, trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "clean-forwarding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.09999997>\n"
     ]
    }
   ],
   "source": [
    "train_step()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "peripheral-arena",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=5.000001>\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    train_step()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beginning-surge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.09999997>\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(0, dtype=tf.float32)\n",
    "x = np.array([1.0, -10.0, 25.0], dtype=np.float32)\n",
    "optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "\n",
    "def cost_fn():\n",
    "    return x[0] * w ** 2 + x[1] * w + x[2]\n",
    "    \n",
    "print(w)\n",
    "optimizer.minimize(cost_fn, [w])\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-spelling",
   "metadata": {},
   "source": [
    "**Note:** the code \n",
    "```python\n",
    ">>> optimizer.minimize(cost_fn, [w])\n",
    "```\n",
    "is a simpler alternative piece of syntax to the lines:\n",
    "```python\n",
    ">>> trainable_variables = [w]\n",
    ">>> grads = tape.gradient(cost, trainable_variables)\n",
    ">>> optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "```\n",
    "\n",
    "Now let's put it in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "reasonable-black",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=5.000001>\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(0, dtype=tf.float32)\n",
    "x = np.array([1.0, -10.0, 25.0], dtype=np.float32)\n",
    "optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "\n",
    "def training(x, w, optimizer):\n",
    "    def cost_fn():\n",
    "        return x[0] * w ** 2 + x[1] * w + x[2]\n",
    "    for i in range(1000):\n",
    "        optimizer.minimize(cost_fn, [w])\n",
    "    \n",
    "    return w\n",
    "    \n",
    "w = training(x, w, optimizer)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-hearing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
